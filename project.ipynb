{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab516c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "try:\n",
    "    fastf1.Cache.enable_cache(\"f1_cache\")\n",
    "except Exception as e:\n",
    "    print(f\"Error enabling cache: {e}. Check cache directory permissions.\")\n",
    "\n",
    "def get_driver_features(driver_code):\n",
    "\n",
    "    driver_characteristics = {\n",
    "     \n",
    "        'VER': {'WetWeatherSkill': 0.95, 'QualifyingPace': 0.95, 'RaceCraft': 0.95, 'Consistency': 0.90, 'Aggression': 0.90, 'TireManagement': 0.85},\n",
    "        'NOR': {'WetWeatherSkill': 0.85, 'QualifyingPace': 0.92, 'RaceCraft': 0.88, 'Consistency': 0.88, 'Aggression': 0.75, 'TireManagement': 0.87},\n",
    "        'PIA': {'WetWeatherSkill': 0.82, 'QualifyingPace': 0.88, 'RaceCraft': 0.84, 'Consistency': 0.85, 'Aggression': 0.78, 'TireManagement': 0.85},\n",
    "        'LEC': {'WetWeatherSkill': 0.82, 'QualifyingPace': 0.95, 'RaceCraft': 0.85, 'Consistency': 0.80, 'Aggression': 0.85, 'TireManagement': 0.80},\n",
    "        'HAM': {'WetWeatherSkill': 0.95, 'QualifyingPace': 0.90, 'RaceCraft': 0.95, 'Consistency': 0.92, 'Aggression': 0.80, 'TireManagement': 0.90},\n",
    "        'RUS': {'WetWeatherSkill': 0.80, 'QualifyingPace': 0.90, 'RaceCraft': 0.85, 'Consistency': 0.85, 'Aggression': 0.83, 'TireManagement': 0.82},\n",
    "        'ANT': {'WetWeatherSkill': 0.78, 'QualifyingPace': 0.85, 'RaceCraft': 0.78, 'Consistency': 0.76, 'Aggression': 0.85, 'TireManagement': 0.75},\n",
    "        'SAI': {'WetWeatherSkill': 0.84, 'QualifyingPace': 0.88, 'RaceCraft': 0.87, 'Consistency': 0.87, 'Aggression': 0.82, 'TireManagement': 0.85},\n",
    "        'ALO': {'WetWeatherSkill': 0.92, 'QualifyingPace': 0.90, 'RaceCraft': 0.95, 'Consistency': 0.90, 'Aggression': 0.88, 'TireManagement': 0.90},\n",
    "        'STR': {'WetWeatherSkill': 0.85, 'QualifyingPace': 0.75, 'RaceCraft': 0.80, 'Consistency': 0.75, 'Aggression': 0.75, 'TireManagement': 0.78},\n",
    "        'TSU': {'WetWeatherSkill': 0.78, 'QualifyingPace': 0.85, 'RaceCraft': 0.82, 'Consistency': 0.75, 'Aggression': 0.90, 'TireManagement': 0.78},\n",
    "        'HAD': {'WetWeatherSkill': 0.75, 'QualifyingPace': 0.80, 'RaceCraft': 0.78, 'Consistency': 0.74, 'Aggression': 0.85, 'TireManagement': 0.74},\n",
    "        'ALB': {'WetWeatherSkill': 0.80, 'QualifyingPace': 0.85, 'RaceCraft': 0.84, 'Consistency': 0.82, 'Aggression': 0.75, 'TireManagement': 0.83},\n",
    "        'GAS': {'WetWeatherSkill': 0.83, 'QualifyingPace': 0.84, 'RaceCraft': 0.85, 'Consistency': 0.83, 'Aggression': 0.80, 'TireManagement': 0.82},\n",
    "        'OCO': {'WetWeatherSkill': 0.80, 'QualifyingPace': 0.82, 'RaceCraft': 0.83, 'Consistency': 0.80, 'Aggression': 0.85, 'TireManagement': 0.78},\n",
    "        'HUL': {'WetWeatherSkill': 0.85, 'QualifyingPace': 0.82, 'RaceCraft': 0.80, 'Consistency': 0.83, 'Aggression': 0.75, 'TireManagement': 0.80},\n",
    "        'BOR': {'WetWeatherSkill': 0.74, 'QualifyingPace': 0.76, 'RaceCraft': 0.76, 'Consistency': 0.74, 'Aggression': 0.82, 'TireManagement': 0.75},\n",
    "        'DOO': {'WetWeatherSkill': 0.74, 'QualifyingPace': 0.78, 'RaceCraft': 0.75, 'Consistency': 0.73, 'Aggression': 0.85, 'TireManagement': 0.74},\n",
    "        'BEA': {'WetWeatherSkill': 0.75, 'QualifyingPace': 0.78, 'RaceCraft': 0.77, 'Consistency': 0.75, 'Aggression': 0.80, 'TireManagement': 0.76},\n",
    "        'LAW': {'WetWeatherSkill': 0.76, 'QualifyingPace': 0.79, 'RaceCraft': 0.78, 'Consistency': 0.75, 'Aggression': 0.85, 'TireManagement': 0.75},\n",
    "        \n",
    "    }\n",
    "    \n",
    "  \n",
    "    default_features = {\n",
    "        'WetWeatherSkill': 0.75, \n",
    "        'QualifyingPace': 0.75, \n",
    "        'RaceCraft': 0.75, \n",
    "        'Consistency': 0.75, \n",
    "        'Aggression': 0.75, \n",
    "        'TireManagement': 0.75\n",
    "    }\n",
    "    \n",
    "    # Return driver features if found, otherwise default\n",
    "    if driver_code in driver_characteristics:\n",
    "        return driver_characteristics[driver_code]\n",
    "    # Try to handle numeric driver codes from historical data\n",
    "    elif str(driver_code) in driver_characteristics:\n",
    "        return driver_characteristics[str(driver_code)]\n",
    "    else:\n",
    "        print(f\"Driver characteristics not found for '{driver_code}'. Using default values.\")\n",
    "        return default_features\n",
    "\n",
    "def get_standings_before_round(year, target_round):\n",
    "\n",
    "    driver_standings = {}\n",
    "    constructor_standings = {}\n",
    "    max_driver_points = 0\n",
    "    max_constructor_points = 0\n",
    "    try:\n",
    "        schedule = fastf1.get_event_schedule(year, include_testing=False)\n",
    "        races_before = schedule[schedule['RoundNumber'] < target_round]\n",
    "\n",
    "        if races_before.empty:\n",
    "            return {}, 0, {}, 0\n",
    "\n",
    "        for index, race in races_before.iterrows():\n",
    "            try:\n",
    "                session = fastf1.get_session(year, race['EventName'], 'R')\n",
    "                session.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "                results = session.results\n",
    "                if results is not None and not results.empty:\n",
    "                    for _, driver_result in results.iterrows():\n",
    "                        driver = driver_result['Abbreviation']\n",
    "                        team = driver_result['TeamName']\n",
    "                        points = driver_result['Points']\n",
    "                        # Update driver standings\n",
    "                        driver_standings[driver] = driver_standings.get(driver, 0) + points\n",
    "                        # Update constructor standings\n",
    "                        constructor_standings[team] = constructor_standings.get(team, 0) + points\n",
    "            except Exception as e:\n",
    "                # Silently continue if a past race fails to load\n",
    "                continue\n",
    "\n",
    "        if driver_standings:\n",
    "            max_driver_points = max(driver_standings.values()) if driver_standings else 0\n",
    "        if constructor_standings:\n",
    "             max_constructor_points = max(constructor_standings.values()) if constructor_standings else 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating standings for {year} before round {target_round}: {e}\")\n",
    "        return {}, 0, {}, 0\n",
    "\n",
    "    return driver_standings, max_driver_points, constructor_standings, max_constructor_points\n",
    "\n",
    "def get_race_data(year, event_identifier):\n",
    "    try:\n",
    "        session_r = fastf1.get_session(year, event_identifier, 'R')\n",
    "        session_r.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "        results_r = session_r.results\n",
    "\n",
    "        if results_r is None or results_r.empty:\n",
    "            print(f\"No race results found for {year} {event_identifier}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        results_r['FinishingPosition'] = pd.to_numeric(results_r['Position'], errors='coerce')\n",
    "        results_r['GridPosition'] = pd.to_numeric(results_r['GridPosition'], errors='coerce')  # Add GridPosition\n",
    "        results_r.dropna(subset=['FinishingPosition', 'GridPosition'], inplace=True)  # Ensure both positions are valid\n",
    "        results_r[['FinishingPosition', 'GridPosition']] = results_r[['FinishingPosition', 'GridPosition']].astype(int)\n",
    "\n",
    "        session_q = fastf1.get_session(year, event_identifier, 'Q')\n",
    "        session_q.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "        results_q = session_q.results\n",
    "\n",
    "        if results_q is None or results_q.empty:\n",
    "            print(f\"No qualifying results found for {year} {event_identifier}. Proceeding without Quali times.\")\n",
    "            qualifying_times = pd.DataFrame({'Abbreviation': results_r['Abbreviation'], 'QualifyingTime (s)': np.nan})\n",
    "        else:\n",
    "            results_q['QualifyingTime'] = results_q[['Q1', 'Q2', 'Q3']].min(axis=1)\n",
    "            results_q['QualifyingTime (s)'] = results_q['QualifyingTime'].dt.total_seconds()\n",
    "            qualifying_times = results_q[['Abbreviation', 'QualifyingTime (s)']].copy()\n",
    "        \n",
    "        race_data = pd.merge(results_r[['Abbreviation', 'TeamName', 'FinishingPosition', 'GridPosition']], \n",
    "                             qualifying_times, on='Abbreviation', how='left')\n",
    "        \n",
    "        race_data['Year'] = year\n",
    "        race_data['RoundNumber'] = session_r.event['RoundNumber']\n",
    "        race_data['EventName'] = session_r.event['EventName']\n",
    "        \n",
    "        # Add driver characteristics\n",
    "        for idx, row in race_data.iterrows():\n",
    "            driver_code = row['Abbreviation']\n",
    "            driver_features = get_driver_features(driver_code)\n",
    "            for feature_name, feature_value in driver_features.items():\n",
    "                race_data.at[idx, feature_name] = feature_value\n",
    "        \n",
    "        # Calculate Points Index *before* this race using the updated function\n",
    "        driver_standings, max_driver_points, constructor_standings, max_constructor_points = get_standings_before_round(year, race_data['RoundNumber'].iloc[0])\n",
    "        \n",
    "        # Calculate Driver Points Index\n",
    "        if max_driver_points > 0:\n",
    "            race_data['PointsIndex'] = race_data['Abbreviation'].apply(lambda x: driver_standings.get(x, 0) / max_driver_points)\n",
    "        else:\n",
    "            race_data['PointsIndex'] = 0.0\n",
    "            \n",
    "        # Calculate Constructor Points Index\n",
    "        if max_constructor_points > 0:\n",
    "            race_data['ConstructorPointsIndex'] = race_data['TeamName'].apply(lambda x: constructor_standings.get(x, 0) / max_constructor_points)\n",
    "        else:\n",
    "             race_data['ConstructorPointsIndex'] = 0.0\n",
    "             \n",
    "        race_data.rename(columns={'Abbreviation': 'Driver', 'TeamName': 'Team'}, inplace=True)\n",
    "        \n",
    "        mean_quali_time = race_data['QualifyingTime (s)'].mean()\n",
    "        race_data['QualifyingTime (s)'] = race_data['QualifyingTime (s)'].fillna(mean_quali_time)\n",
    "        \n",
    "        # Ensure no NaNs remain in core features\n",
    "        core_features = ['Driver', 'Team', 'FinishingPosition', 'QualifyingTime (s)', \n",
    "                         'PointsIndex', 'ConstructorPointsIndex', 'GridPosition']\n",
    "        driver_feature_keys = list(get_driver_features('VER').keys())  # Get a sample of driver feature keys\n",
    "        core_features.extend(driver_feature_keys)\n",
    "        race_data.dropna(subset=core_features, inplace=True)\n",
    "        \n",
    "        # Include driver features in the returned columns\n",
    "        return_columns = ['Year', 'EventName', 'Driver', 'Team', 'QualifyingTime (s)', \n",
    "                          'PointsIndex', 'ConstructorPointsIndex', 'GridPosition', 'FinishingPosition']\n",
    "        return_columns.extend(driver_feature_keys)\n",
    "        \n",
    "        return race_data[return_columns]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {year} {event_identifier}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_YEAR = 2025\n",
    "TARGET_GP_NAME = 'Japanese' \n",
    "HISTORICAL_YEARS = range(TARGET_YEAR - 1, 2017, -1) \n",
    "\n",
    "\n",
    "all_race_data = []\n",
    "\n",
    "try:\n",
    "    schedule_target_year = fastf1.get_event_schedule(TARGET_YEAR, include_testing=False)\n",
    "    target_event = schedule_target_year[schedule_target_year['EventName'].str.contains(TARGET_GP_NAME, case=False, na=False)]\n",
    "    \n",
    "    if target_event.empty:\n",
    "        raise ValueError(f\"Target GP '{TARGET_GP_NAME}' not found in {TARGET_YEAR} schedule.\")\n",
    "        \n",
    "    target_round = target_event['RoundNumber'].iloc[0]\n",
    "    target_venue = target_event['Location'].iloc[0]\n",
    "    target_event_name = target_event['EventName'].iloc[0] # Official name for consistency\n",
    "    print(f\"Target Event: {TARGET_YEAR} {target_event_name} (Round {target_round}, Venue: {target_venue})\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error finding target GP info: {e}\")\n",
    "\n",
    "# 2. Get Data from Current Season (up to target GP)\n",
    "print(f\"\\n--- Fetching {TARGET_YEAR} data before Round {target_round} ---\")\n",
    "schedule_current_year_filtered = schedule_target_year[schedule_target_year['RoundNumber'] < target_round]\n",
    "for index, race in schedule_current_year_filtered.iterrows():\n",
    "    print(f\"Processing {TARGET_YEAR} {race['EventName']}...\")\n",
    "    data = get_race_data(TARGET_YEAR, race['EventName'])\n",
    "    if data is not None:\n",
    "        all_race_data.append(data)\n",
    "\n",
    "# 3. Get Historical Data\n",
    "print(f\"\\n--- Fetching Historical Data ---\")\n",
    "for year in HISTORICAL_YEARS:\n",
    "    try:\n",
    "        schedule_hist = fastf1.get_event_schedule(year, include_testing=False)\n",
    "        print(f\"Processing all races for {year}...\")\n",
    "        # Iterate through all races in the historical year's schedule\n",
    "        for index, race_hist in schedule_hist.iterrows():\n",
    "            event_name_hist = race_hist['EventName']\n",
    "            print(f\"  Processing {year} {event_name_hist}...\")\n",
    "            data = get_race_data(year, event_name_hist)\n",
    "            if data is not None:\n",
    "                all_race_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting schedule or processing races for {year}: {e}\")\n",
    "\n",
    "# 4. Combine Data\n",
    "if not all_race_data:\n",
    "    raise ValueError(\"No data could be collected. Check FastF1 setup and GP/Year validity.\")\n",
    "\n",
    "combined_data = pd.concat(all_race_data, ignore_index=True)\n",
    "\n",
    "# Drop the RoundNumber column\n",
    "if 'RoundNumber' in combined_data.columns:\n",
    "    combined_data.drop(columns=['RoundNumber'], inplace=True)\n",
    "    print(\"Dropped 'RoundNumber' column.\")\n",
    "else:\n",
    "    print(\"'RoundNumber' column not found in combined_data.\")\n",
    "\n",
    "print(f\"\\n--- Combined Data Shape after dropping RoundNumber: {combined_data.shape} ---\")\n",
    "print(combined_data.head())\n",
    "print(combined_data.info())\n",
    "print(combined_data.describe())\n",
    "\n",
    "# Export the combined dataset to CSV\n",
    "try:\n",
    "    csv_filename = 'combined_f1_data.csv'\n",
    "    combined_data.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\n--- Full Combined Dataset exported to {csv_filename} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError exporting data to CSV: {e}\")\n",
    "\n",
    "# 5. Prepare Data for Target Race Prediction\n",
    "print(f\"\\n--- Preparing data for {TARGET_YEAR} {target_event_name} prediction ---\")\n",
    "try:\n",
    "    # Get Qualifying data for the actual target race\n",
    "    target_q_session = fastf1.get_session(TARGET_YEAR, target_event_name, 'Q')\n",
    "    target_q_session.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "    target_q_results = target_q_session.results\n",
    "    \n",
    "    if target_q_results is None or target_q_results.empty:\n",
    "         raise ValueError(f\"Could not load Qualifying results for target event: {TARGET_YEAR} {target_event_name}\")\n",
    "         \n",
    "    target_q_results['QualifyingTime'] = target_q_results[['Q1', 'Q2', 'Q3']].min(axis=1)\n",
    "    target_q_results['QualifyingTime (s)'] = target_q_results['QualifyingTime'].dt.total_seconds()\n",
    "    \n",
    "    # Get points index before the target race using the updated function\n",
    "    target_driver_standings, target_max_driver_points, target_constructor_standings, target_max_constructor_points = get_standings_before_round(TARGET_YEAR, target_round)\n",
    "    \n",
    "    # Create DataFrame for prediction\n",
    "    predict_df = target_q_results[['Abbreviation', 'TeamName', 'QualifyingTime (s)']].copy()\n",
    "    predict_df.rename(columns={'Abbreviation': 'Driver', 'TeamName': 'Team'}, inplace=True)\n",
    "    \n",
    "    # Calculate Driver Points Index for prediction set\n",
    "    if target_max_driver_points > 0:\n",
    "         predict_df['PointsIndex'] = predict_df['Driver'].apply(lambda x: target_driver_standings.get(x, 0) / target_max_driver_points)\n",
    "    else:\n",
    "         predict_df['PointsIndex'] = 0.0\n",
    "         \n",
    "    # Calculate Constructor Points Index for prediction set\n",
    "    if target_max_constructor_points > 0:\n",
    "         predict_df['ConstructorPointsIndex'] = predict_df['Team'].apply(lambda x: target_constructor_standings.get(x, 0) / target_max_constructor_points)\n",
    "    else:\n",
    "         predict_df['ConstructorPointsIndex'] = 0.0\n",
    "         \n",
    "    # Handle potential missing Quali times in prediction set (e.g., pit lane start)\n",
    "   \n",
    "    mean_quali_train = combined_data['QualifyingTime (s)'].mean()\n",
    "    predict_df['QualifyingTime (s)'] = predict_df['QualifyingTime (s)'].fillna(mean_quali_train)\n",
    "    \n",
    "    # Sort the qualifying results by time to determine grid positions\n",
    "    predict_df = predict_df.sort_values('QualifyingTime (s)')\n",
    "    predict_df['GridPosition'] = range(1, len(predict_df) + 1)\n",
    "    \n",
    "    # Add driver features to the prediction dataframe for the target race\n",
    "    for idx, row in predict_df.iterrows():\n",
    "        driver_code = row['Driver']\n",
    "        driver_features = get_driver_features(driver_code)\n",
    "        for feature_name, feature_value in driver_features.items():\n",
    "            predict_df.at[idx, feature_name] = feature_value\n",
    "    \n",
    "    # Ensure no NaNs in prediction features\n",
    "    predict_df.dropna(subset=['QualifyingTime (s)', 'PointsIndex', 'ConstructorPointsIndex'], inplace=True)\n",
    "    \n",
    "    # Keep track of drivers for final output\n",
    "    predict_drivers = predict_df['Driver'].tolist()\n",
    "    \n",
    "    print(f\"Prediction input data shape: {predict_df.shape}\")\n",
    "    print(predict_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error preparing prediction data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56213c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['GridPosition', 'QualifyingTime (s)', 'PointsIndex', 'ConstructorPointsIndex','QualifyingPace', 'RaceCraft', 'Consistency', 'Aggression', 'TireManagement']\n",
    "target = 'FinishingPosition'\n",
    "\n",
    "X = combined_data[features].copy()\n",
    "y = combined_data[target].copy()\n",
    "\n",
    "predict_X = predict_df[features].copy()\n",
    "\n",
    "\n",
    "print(predict_X.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.2, \n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted_scores = model.predict(predict_X)\n",
    "\n",
    "#Create Ranked Results\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Driver': predict_drivers, \n",
    "    'PredictedScore': predicted_scores\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values(by='PredictedScore')\n",
    "# Assign ranks \n",
    "results_df['PredictedFinishingPosition'] = np.arange(1, len(results_df) + 1)\n",
    "\n",
    "\n",
    "print(f\"\\Predicted Finishing Order for {TARGET_YEAR} {target_event_name} \\n\")\n",
    "print(results_df[['Driver', 'PredictedFinishingPosition']].to_string(index=False))\n",
    "\n",
    "\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred_test = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "print(f\"Mean Absolute Error on test set is {mae:.2f} positions\")\n",
    "\n",
    "print(\"\\nFeature Importance\")\n",
    "try:\n",
    "    feature_names = X.columns\n",
    "    importances = model.feature_importances_\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    print(importance_df.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate or display feature importances: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for Random Forest Regressor Implementation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Assuming train_test_split and mean_absolute_error are already imported\n",
    "# Assuming combined_data, predict_df, predict_drivers, X_train, X_test, y_train, y_test are available\n",
    "\n",
    "print(\"\\\\n--- Preparing Data for Random Forest Regressor ---\")\n",
    "\n",
    "# Use the same features and target as before\n",
    "features_rf = ['GridPosition', 'QualifyingTime (s)', 'PointsIndex', 'ConstructorPointsIndex',\n",
    "               'QualifyingPace', 'RaceCraft', 'Consistency', 'Aggression', 'TireManagement']\n",
    "target_rf = 'FinishingPosition'\n",
    "\n",
    "# use training and test set from gradient boosting \n",
    "\n",
    "# --- Model Training ---\n",
    "print(\"\\\\n--- Training Random Forest Regressor ---\")\n",
    "\n",
    "rf_regressor = RandomForestRegressor(\n",
    "    n_estimators=100,      \n",
    "    max_depth=None,         \n",
    "    min_samples_split=2,    \n",
    "    min_samples_leaf=1,    \n",
    "    random_state=42,\n",
    "    n_jobs=-1              \n",
    ")\n",
    "\n",
    "rf_regressor.fit(X_train, y_train) \n",
    "\n",
    "# --- Prediction ---\n",
    "print(f\"\\\\n--- Predicting with Random Forest Regressor for {TARGET_YEAR} {target_event_name} ---\")\n",
    "\n",
    "\n",
    "predict_X_rf = predict_df[features_rf].copy() \n",
    "\n",
    "predicted_rf_scores = rf_regressor.predict(predict_X_rf)\n",
    "\n",
    "# Create Ranked Results\n",
    "results_rf_df = pd.DataFrame({\n",
    "    'Driver': predict_drivers, \n",
    "    'PredictedRFScore': predicted_rf_scores \n",
    "})\n",
    "\n",
    "results_rf_df = results_rf_df.sort_values(by='PredictedRFScore')\n",
    "results_rf_df['PredictedFinishingPosition'] = np.arange(1, len(results_rf_df) + 1)\n",
    "\n",
    "print(f\"\\\\nPredicted Finishing Order (Random Forest) for {TARGET_YEAR} {target_event_name}\\\\n\")\n",
    "print(results_rf_df[['Driver', 'PredictedFinishingPosition']].to_string(index=False))\n",
    "\n",
    "# --- Evaluation ---\n",
    "print(\"\\\\n--- Evaluating Random Forest Model Performance ---\")\n",
    "y_pred_test_rf = rf_regressor.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_test_rf) \n",
    "print(f\"Mean Absolute Error on test set is {mae_rf:.2f} positions\")\n",
    "\n",
    "# --- Feature Importance ---\n",
    "print(\"\\\\nFeature Importance (Random Forest)\")\n",
    "try:\n",
    "    feature_names_rf = X_train.columns\n",
    "    importances_rf = rf_regressor.feature_importances_\n",
    "    importance_rf_df = pd.DataFrame({'Feature': feature_names_rf, 'Importance': importances_rf})\n",
    "    importance_rf_df = importance_rf_df.sort_values(by='Importance', ascending=False)\n",
    "    print(importance_rf_df.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate or display feature importances: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LambdaMART Implementation\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import ndcg_score \n",
    "\n",
    "print(\"\\\\n--- Preparing Data for LambdaMART (LightGBM Ranker) ---\")\n",
    "\n",
    "\n",
    "features_ltr = ['Driver', 'GridPosition', 'QualifyingTime (s)', 'PointsIndex', 'ConstructorPointsIndex', \n",
    "                        'QualifyingPace', 'RaceCraft', 'Consistency', 'Aggression', 'TireManagement']\n",
    "target_ltr = 'RelevanceScore' # We'll create this\n",
    "\n",
    "\n",
    "combined_data_ltr = combined_data.copy()\n",
    "combined_data_ltr['Driver'] = combined_data_ltr['Driver'].astype('category')\n",
    "combined_data_ltr[target_ltr] = 21 - combined_data_ltr['FinishingPosition'] \n",
    "\n",
    "# Create Query Groups (Essential for LTR)\n",
    "# Group by Year and EventName to identify individual races (queries)\n",
    "combined_data_ltr['QueryID'] = combined_data_ltr.groupby(['Year', 'EventName']).ngroup()\n",
    "query_groups_train = combined_data_ltr.groupby('QueryID').size().tolist()\n",
    "\n",
    "X_ltr = combined_data_ltr[features_ltr]\n",
    "y_ltr = combined_data_ltr[target_ltr]\n",
    "groups_ltr = combined_data_ltr['QueryID']\n",
    "\n",
    "print(\"\\\\n--- Training LambdaMART (LightGBM Ranker) ---\")\n",
    "\n",
    "\n",
    "lgbm_ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",  \n",
    "    ndcg_eval_at=[1, 3, 5, 10], \n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    # its using gradeint boositng by default\n",
    ")\n",
    "\n",
    "\n",
    "lgbm_ranker.fit(X_ltr, y_ltr, group=query_groups_train, categorical_feature=['Driver']) \n",
    "\n",
    "\n",
    "print(f\"\\\\n--- Predicting with LambdaMART for {TARGET_YEAR} {target_event_name} ---\")\n",
    "\n",
    "# Prepare prediction data (already done in previous cell as predict_X)\n",
    "predict_df['Driver'] = predict_df['Driver'].astype('category')\n",
    "predict_X_ltr = predict_df[features_ltr].copy() \n",
    "\n",
    "# Predict relevance scores\n",
    "predicted_ltr_scores = lgbm_ranker.predict(predict_X_ltr)\n",
    "\n",
    "# Create Ranked Results\n",
    "results_ltr_df = pd.DataFrame({\n",
    "    'Driver': predict_drivers, \n",
    "    'PredictedLTRScore': predicted_ltr_scores # Higher score is better\n",
    "})\n",
    "\n",
    "# Sort by the predicted score in descending order\n",
    "results_ltr_df = results_ltr_df.sort_values(by='PredictedLTRScore', ascending=False)\n",
    "\n",
    "# Assign ranks based on the sorted scores\n",
    "results_ltr_df['PredictedFinishingPosition'] = np.arange(1, len(results_ltr_df) + 1)\n",
    "\n",
    "print(f\"\\\\nPredicted Finishing Order (LambdaMART) for {TARGET_YEAR} {target_event_name}\\\\n\")\n",
    "print(results_ltr_df[['Driver', 'PredictedFinishingPosition']].to_string(index=False))\n",
    "\n",
    "print(\"\\\\nFeature Importance (LambdaMART)\")\n",
    "try:\n",
    "    feature_names_ltr = X_ltr.columns\n",
    "    importances_ltr = lgbm_ranker.feature_importances_\n",
    "    importance_ltr_df = pd.DataFrame({'Feature': feature_names_ltr, 'Importance': importances_ltr})\n",
    "    importance_ltr_df = importance_ltr_df.sort_values(by='Importance', ascending=False)\n",
    "    print(importance_ltr_df.to_string(index=False))\n",
    "except Exception as e:\n",
    "        print(\"Could not calculate or display feature importances: {}\".format(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
